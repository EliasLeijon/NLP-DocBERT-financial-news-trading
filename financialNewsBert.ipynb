{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox7G3ZYq4yjt"
      },
      "source": [
        "## Importing swe-BERT for initial training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_lPyCgF4yjw",
        "outputId": "2fefa19d-79f2-472c-bb6b-eccec296f0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import math\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)\n",
        "# collab command to install transformers\n",
        "!pip install transformers\n",
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XOPF9_mE4yjx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "import re\n",
        "def clean_txt (text):\n",
        "  text = re.sub(\"ยน\", \"\", text)\n",
        "  text=re.sub(\"(\\\\W)+\",\"  \", text)\n",
        "  return text\n",
        "\n",
        "\n",
        "class SNLIDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, max_size=None):\n",
        "        super().__init__()\n",
        "        self.xs = []\n",
        "        self.ys = []\n",
        "        self.sentence_lengths = np.array([])\n",
        "        count = 0\n",
        "        with open(filename, encoding=\"utf-8\") as source:\n",
        "            for i, line in enumerate(source):\n",
        "                if i == 0:\n",
        "                  continue\n",
        "                # print(line)\n",
        "                if max_size and i >= max_size:\n",
        "                    break\n",
        "                try:\n",
        "                  sentence, sentiment_value = line.rstrip().split('|') # Delimeter to be chosen\n",
        "                  count += 1\n",
        "                except:\n",
        "                  print( \"Error when processing the following data \", [line.rstrip().split('|')])\n",
        "                # print(sentence)\n",
        "                self.xs.append(clean_txt(sentence))\n",
        "                self.ys.append(int(sentiment_value)) # make sure negative/neutral/positive is labelled correct\n",
        "                self.sentence_lengths = np.append(self.sentence_lengths, len(sentence.split(\" \")))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.xs[idx], self.ys[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "class SNLIDataset_shell_class(SNLIDataset):\n",
        "    def __init__(self, xs, ys, sentence_lengths):\n",
        "      self.xs = xs\n",
        "      self.ys = ys\n",
        "      self.sentence_lengths = sentence_lengths"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_dataset_to_train_and_test(SNLIDataset, percentage_to_train):\n",
        "    random_indices = torch.randperm(len(SNLIDataset.xs))\n",
        "    num_of_sent_in_train = math.floor(len(SNLIDataset.xs)*(percentage_to_train))\n",
        " \n",
        "    train_dataset_xs = list(map(SNLIDataset.xs.__getitem__, random_indices[0:num_of_sent_in_train]))\n",
        "    train_dataset_ys = list(map(SNLIDataset.ys.__getitem__, random_indices[0:num_of_sent_in_train]))\n",
        "    train_dataset_sent_lengths = list(map(SNLIDataset.sentence_lengths.__getitem__, random_indices[0:num_of_sent_in_train]))\n",
        "\n",
        "\n",
        "    test_dataset_xs = list(map(SNLIDataset.xs.__getitem__, random_indices[num_of_sent_in_train:]))\n",
        "    test_dataset_ys = list(map(SNLIDataset.ys.__getitem__, random_indices[num_of_sent_in_train:]))\n",
        "    test_dataset_sent_lengths = list(map(SNLIDataset.sentence_lengths.__getitem__, random_indices[num_of_sent_in_train:]))\n",
        "  \n",
        "    train_dataset = SNLIDataset_shell_class(train_dataset_xs, train_dataset_ys, train_dataset_sent_lengths)\n",
        "\n",
        "    test_dataset = SNLIDataset_shell_class(test_dataset_xs, test_dataset_ys, test_dataset_sent_lengths)\n",
        "    \n",
        "\n",
        "    return train_dataset, test_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "WggYx43umASg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrCpUve_4yjy"
      },
      "source": [
        "## Create all datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "NU2qKdwb4yjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05bd78a-fa8f-463b-b0ac-251e0e2ac8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27000\n",
            "tensor([ 9268,  7576, 18391,  ...,  6731, 25463, 24912])\n",
            "30000\n",
            "27000\n",
            "3000\n"
          ]
        }
      ],
      "source": [
        "# financial_news_train_dataset = SNLIDataset('./Financial Data/financial_phrases_labeled_psv_train.csv')\n",
        "# financial_news_test_dataset = SNLIDataset('./Financial Data/financial_phrases_labeled_psv_test.csv')\n",
        "amazon_review_dataset = SNLIDataset('./amazon-review-data/amazon_review_data_psv.csv')\n",
        "# hp_n, mp_n, neg_n, neu_n = SNLIDataset('./sweOnlyProcData/highPosNews.txt'), SNLIDataset('./sweOnlyProcData/mediumPosNews.txt'), SNLIDataset('./sweOnlyProcData/negativeNews.txt'), SNLIDataset('./sweOnlyProcData/neutralNews.txt')\n",
        "\n",
        "# data = financial_news_train_dataset[121]\n",
        "\n",
        "train, test = divide_dataset_to_train_and_test(amazon_review_dataset, 0.9)\n",
        "\n",
        "print(len(amazon_review_dataset))\n",
        "print(len(train))\n",
        "print(len(test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCW4rqz4uF31"
      },
      "source": [
        "## Dataset analysis\n",
        "Here we analyze the length distribution for each dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "hCIcaM4quF31",
        "outputId": "438b93bf-6f0e-4ae6-d942-f7f2f1066ff4"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4dba08fdad1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplot_data_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_plots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplot_data_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamazon_review_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amazon_review_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_data_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinancial_news_test_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinancial_news_train_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"financial_news_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplot_data_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhp_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneu_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_lengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Own-collected-news\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'financial_news_test_dataset' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_length(sentence_lengths, datasetName, resolution=1):\n",
        "    plot_data_length.total_plots += 1\n",
        "    plt.figure(plot_data_length.total_plots)\n",
        "    plt.hist(sentence_lengths, bins=int(np.max(sentence_lengths)*resolution), density=True)\n",
        "    plt.xlabel(datasetName)\n",
        "plot_data_length.total_plots = 0\n",
        "plot_data_length(amazon_review_dataset.sentence_lengths, \"amazon_review_dataset\", 1/50)\n",
        "plot_data_length(np.concatenate([financial_news_test_dataset.sentence_lengths, financial_news_train_dataset.sentence_lengths]), \"financial_news_dataset\", 1/4)\n",
        "plot_data_length(np.concatenate([hp_n.sentence_lengths, mp_n.sentence_lengths, neg_n.sentence_lengths, neu_n.sentence_lengths]), \"Own-collected-news\", 1/500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0tgZwEq4yj0"
      },
      "source": [
        "## Import swedish bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngd8efgP4yj0",
        "outputId": "583a684c-8b25-4ac2-91d0-774576edcb81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from transformers.modeling_outputs import BaseModelOutputWithPooling\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('KB/bert-base-swedish-cased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "ojp1xQBq4yj0",
        "outputId": "76ac9a02-8776-418e-bb82-ca5fce196bef"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d8fd32348707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinancial_news_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancial_news_train_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'financial_news_train_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "tokenized = tokenizer(text=financial_news_train_dataset[1][0], padding='longest', return_tensors='pt')\n",
        "print(financial_news_train_dataset[1][0])\n",
        "print(tokenized.input_ids)\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyx9uwrO4yj1"
      },
      "source": [
        "### Define colate function that tokenizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB98CebIuF33"
      },
      "outputs": [],
      "source": [
        "def get_split(text1):\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  if text1.shape[0]//150 >0:\n",
        "    n = text1.shape[0]//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = text1[:200]\n",
        "      l_total.append(l_parcial)\n",
        "    else:\n",
        "      l_parcial = text1[w*150:w*150 + 200]\n",
        "      l_total.append(l_parcial)\n",
        "  return l_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASAcPEuauF33"
      },
      "outputs": [],
      "source": [
        "def tensor_split(text1, seq_size=200, overlap=50, add_to_start = 2):\n",
        "  l_total = []\n",
        "  l_parcial = []\n",
        "  cls_tokens = torch.unsqueeze(torch.as_tensor([add_to_start]* text1.shape[0]), dim=1)\n",
        "  if text1.shape[1]//(seq_size-overlap) >0:\n",
        "    n = text1.shape[1]//(seq_size-overlap)\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_parcial = torch.concat([cls_tokens, text1[:,:seq_size]], dim=1)\n",
        "      l_total.append(l_parcial.to(device))\n",
        "    else:\n",
        "      l_parcial = torch.concat([cls_tokens, text1[:,w*(seq_size-overlap):w*(seq_size-overlap) + seq_size]], dim=1)\n",
        "      l_total.append(l_parcial.to(device))\n",
        "  return l_total\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n42CPT4o4yj1"
      },
      "outputs": [],
      "source": [
        "def our_collate_fn(data):\n",
        "    x = [a[0] for a in data]\n",
        "    y = [a[1] for a in data]\n",
        "    tokenized = tokenizer(text=x, padding='longest', return_tensors='pt')\n",
        "\n",
        "    return tokenized['input_ids'], torch.as_tensor(y), tokenized['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULmii5oWuF33"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def create_training_examples(dataset, batch_size = 64, seq_size = 200, overlap = 50):\n",
        "    batch_sort_order = np.array_split(dataset.sentence_lengths.argsort()[::-1], round(len(dataset) / batch_size))\n",
        "    tokenized_train_data = DataLoader(dataset, collate_fn=our_collate_fn, batch_sampler=batch_sort_order) #\n",
        "\n",
        "    for bindex, (bx, by, ba) in enumerate(tokenized_train_data):\n",
        "        yield tensor_split(bx, seq_size, overlap), tensor_split(ba, seq_size, overlap, add_to_start=1), by.to(device)\n",
        "                \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXhye472uF34",
        "outputId": "587148ee-37af-4d83-e284-0303e9b5369a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape: [3, 5, 10]\n",
            "Output shape: [3, 5, 20]\n",
            "Last hidden state shape: [1, 3, 20]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "rnn = nn.LSTM(10, 20, batch_first = True)\n",
        "input = torch.randn(3, 5, 10)\n",
        "h0 = torch.randn(1, 3, 20)\n",
        "c0 = torch.randn(1, 3, 20)\n",
        "output, (hn, cn) = rnn(input, (h0, c0))\n",
        "\n",
        "print(\"Input shape: {}\".format([*input.shape]))\n",
        "print(\"Output shape: {}\".format([*output.shape]))\n",
        "print(\"Last hidden state shape: {}\".format([*hn.shape]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y35jjoeIuF34",
        "outputId": "5b9b5b70-a0b2-442f-d227-1cb447a9ad59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at KB/bert-base-swedish-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DocBert(nn.Module):\n",
        "    def __init__(self, bert, hidden_dim, num_labels):\n",
        "        super().__init__()\n",
        "        self.bert =  bert.to(device) # INTE BertForSequenceClassification\n",
        "        self.lstm = nn.LSTM(bert.config.hidden_size, hidden_dim, batch_first=True).to(device)\n",
        "        # Input [Batch_size, sequence_length, input_size]\n",
        "        # Output [1, batch_size, hidden_dim]\n",
        "        self.linear = nn.Linear(hidden_dim, num_labels).to(device)\n",
        "    def forward(self, x_seqs, a_seqs):\n",
        "      output = []\n",
        "      for x_seq, a_seq in zip(x_seqs, a_seqs):\n",
        "        output.append(self.bert(x_seq, a_seq).pooler_output)#Only get the embedding of the [CLS]-token [batch_size, number_of_sequences, input_size]\n",
        "      _ , (output, _) = self.lstm(torch.stack(output, dim=1)) # [1, batch_size, hidden_dim]\n",
        "      return self.linear(torch.squeeze(output, dim=0))\n",
        "      #   bertified_seqs.append()\n",
        "      # self.lstm(, )\n",
        "\n",
        "    def predict(self, ):\n",
        "      pass\n",
        "\n",
        "\n",
        "bert = BertModel.from_pretrained('KB/bert-base-swedish-cased')\n",
        "docbert = DocBert(bert, 20, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc3wjfjP4yj2"
      },
      "source": [
        "#### Functions for training and testing a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzLbWwOxR3Qf",
        "outputId": "05afdc7b-4ccd-4e88-8f22-bcbb694e23f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.9039, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6511, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8047, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6983, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7511, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7340, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8056, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7440, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7988, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7700, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7331, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8559, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7775, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6545, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7999, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6233, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7180, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7492, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7409, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6742, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6785, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7301, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6941, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5355, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.9667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6300, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7991, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6858, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7122, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7116, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6888, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5432, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.8520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7465, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6187, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5945, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6789, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4136, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6776, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6444, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6273, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4914, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5545, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3827, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4630, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5129, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.6182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2282, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2785, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1979, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "optimizer = torch.optim.Adam(docbert.parameters())\n",
        "i = 0\n",
        "tot_loss = 0\n",
        "for x_seqs, a_seqs, by in create_training_examples(amazon_review_dataset, batch_size=8, seq_size=200, overlap=50):\n",
        "  optimizer.zero_grad()\n",
        "  preds = docbert.forward(x_seqs, a_seqs)\n",
        "  loss = F.cross_entropy(preds, by)\n",
        "  tot_loss += loss\n",
        "  i += 1\n",
        "  if i % 10 == 0:\n",
        "    print(tot_loss / 10)\n",
        "    tot_loss = 0\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOjHNMEv4yj2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "def train_model(train_data, batch_size):\n",
        "  batch_sort_order = np.array_split(train_data.sentence_lengths.argsort()[::-1], round(len(train_data) / batch_size))\n",
        "  tokenized_train_data = DataLoader(train_data, collate_fn=our_collate_fn, batch_sampler=batch_sort_order) #\n",
        "  \n",
        "  # print(tokenized_train_data)\n",
        "  # for batch in tokenized_train_data:\n",
        "  #     for sent_pair in batch[0]:\n",
        "  #       print(sent_pair)\n",
        "  #     print(batch)\n",
        "  #     break\n",
        "  \n",
        "\n",
        "  model = BertForSequenceClassification.from_pretrained('KB/bert-base-swedish-cased', num_labels=3)\n",
        "  model = model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "  # softmax = torch.nn.Softmax(dim=1)\n",
        "  epochs = 1\n",
        "\n",
        "  for _ in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    with tqdm(total=len(train_data)) as pbar:\n",
        "\n",
        "      for bindex, (bx, by, ba) in enumerate(tokenized_train_data):\n",
        "        bx, by, ba = bx.to(device), by.to(device), ba.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass\n",
        "        train_output = model(bx, labels=by, attention_mask=ba)\n",
        "        # backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.update(len(bx))\n",
        "  return model\n",
        "\n",
        "def evaluate_model(model, valid_data, batch_size):\n",
        "    batch_sort_order = np.array_split(valid_data.sentence_lengths.argsort()[::-1], round(len(valid_data) / batch_size))\n",
        "    tokenized_valid_data = DataLoader(valid_data, batch_sampler=batch_sort_order, collate_fn=our_collate_fn)\n",
        "    model.eval()\n",
        "    valids = []\n",
        "    for bx, by, ba in tokenized_valid_data:\n",
        "      with torch.no_grad():\n",
        "        bx, by, ba = bx.to(device), by.to(device), ba.to(device)\n",
        "        # forward pass\n",
        "        try:\n",
        "          eval_output = model(bx, attention_mask=ba)\n",
        "          guess = torch.argmax(eval_output.logits, dim=1)\n",
        "          valids.append(sum(guess == by)/len(by))\n",
        "        except Exception as e:\n",
        "          print(bx.shape, by.shape)\n",
        "          print(ba.shape)\n",
        "          print(e)\n",
        "        \n",
        "    print('Accuracy: {}'.format(sum(valids)/len(valids)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lnkrQf9sEhx"
      },
      "source": [
        "## Train and save the financial model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "9QzggwTk4yj2",
        "outputId": "4678a497-4599-4605-a8f6-42d23af7f492"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-d61c55308954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinancial_trained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancial_news_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancial_trained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinancial_news_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfinancial_trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./financial_trained_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-a9493a9cd95e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KB/bert-base-swedish-cased'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2424\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m                 \u001b[0;31m# Time to load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m             \u001b[0;31m# set dtype to instantiate the model under:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_load_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mtyped_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m         typed_storage._storage._set_from_file(\n\u001b[0m\u001b[1;32m   1021\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             torch._utils._element_size(typed_storage.dtype))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "financial_trained_model = train_model(financial_news_train_dataset, 64)\n",
        "evaluate_model(financial_trained_model, financial_news_test_dataset)\n",
        "financial_trained_model.save_pretrained(\"./financial_trained_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSzk4FKwsMni"
      },
      "source": [
        "## Load the financial model and evaluate it on similar test-data \n",
        "accuracy should be 88%+"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGjjZWoQdFxa",
        "outputId": "1ffe247c-a3f2-456f-a76c-34d1f99e6c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8862680196762085\n"
          ]
        }
      ],
      "source": [
        "loadedModel = BertForSequenceClassification.from_pretrained(\"./financial_trained_model/\")\n",
        "evaluate_model(loadedModel, financial_news_test_dataset, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPXYKeFSqEhS",
        "outputId": "06c83920-dddf-46cb-b3d2-e9d469ab3e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.39497217535972595\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(loadedModel, amazon_review_dataset, 16)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vCW4rqz4uF31"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "43b1b630598a744212fd16e5095ab3aa6d4637b887bcabe04ae192328f97bb8f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}